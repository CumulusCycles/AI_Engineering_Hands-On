{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8e47e88",
      "metadata": {},
      "source": [
        "# Notebook 1: Function Calling\n",
        "\n",
        "Give the model a set of tools — it decides which one to call, with what arguments, based on the question. No hardcoded routing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd2e1e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
        "from tools import TOOL_SCHEMAS, TOOL_FUNCTIONS\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI()\n",
        "MODEL = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8057be62",
      "metadata": {},
      "source": [
        "## Part 1: Inspect the tool schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc15870",
      "metadata": {},
      "outputs": [],
      "source": [
        "# The model reads these schemas to decide when and how to call each tool.\n",
        "for schema in TOOL_SCHEMAS:\n",
        "    print(json.dumps(schema, indent=2))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "083a581c",
      "metadata": {},
      "source": [
        "## Part 2: Send a question — get a tool call back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb5258e",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What does Agentic AI Liability Insurance cover?\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You are a helpful assistant for AI Agent Insure. \"\n",
        "            \"Use the available tools to answer questions accurately. \"\n",
        "            \"Do not guess — if a tool can answer the question, use it.\"\n",
        "        )\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": question}\n",
        "]\n",
        "\n",
        "# tool_choice=\"auto\" — the model decides whether to call a tool or answer directly.\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=messages,\n",
        "    tools=TOOL_SCHEMAS,\n",
        "    tool_choice=\"auto\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"Stop reason:\", response.choices[0].finish_reason)\n",
        "print()\n",
        "print(\"Full response message:\")\n",
        "print(response.choices[0].message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b077ac2a",
      "metadata": {},
      "source": [
        "## Part 3: Inspect the tool call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e2b393",
      "metadata": {},
      "outputs": [],
      "source": [
        "# tool_calls contains: id, function.name, function.arguments (JSON string)\n",
        "tool_call = response.choices[0].message.tool_calls[0]\n",
        "\n",
        "print(\"Tool the model wants to call:\", tool_call.function.name)\n",
        "print(\"Arguments (raw JSON string):  \", tool_call.function.arguments)\n",
        "print()\n",
        "\n",
        "args = json.loads(tool_call.function.arguments)\n",
        "print(\"Arguments (parsed dict):      \", args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9727b9",
      "metadata": {},
      "source": [
        "## Part 4: Execute the tool, feed the result back, get the final answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a3dd7d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "fn = TOOL_FUNCTIONS[tool_call.function.name]\n",
        "tool_result = fn(**args)\n",
        "print(\"Tool returned:\", tool_result)\n",
        "print()\n",
        "\n",
        "# Append the model's tool_call message, then the tool result with role=\"tool\".\n",
        "# tool_call_id links this result back to the specific call the model made.\n",
        "messages.append(response.choices[0].message)\n",
        "messages.append({\n",
        "    \"role\": \"tool\",\n",
        "    \"tool_call_id\": tool_call.id,\n",
        "    \"content\": tool_result\n",
        "})\n",
        "\n",
        "# Second API call — model reads the result and writes the final answer.\n",
        "final_response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=messages,\n",
        "    tools=TOOL_SCHEMAS,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"Stop reason:\", final_response.choices[0].finish_reason)\n",
        "print()\n",
        "print(\"Final answer:\")\n",
        "print(final_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8698c772",
      "metadata": {},
      "source": [
        "## Part 5: Three questions — three different tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5877ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "def single_tool_call_demo(question: str) -> None:\n",
        "    msgs = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a helpful assistant for AI Agent Insure. \"\n",
        "                \"Use the available tools to answer questions accurately.\"\n",
        "            )\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    r1 = client.chat.completions.create(\n",
        "        model=MODEL, messages=msgs, tools=TOOL_SCHEMAS,\n",
        "        tool_choice=\"auto\", temperature=0\n",
        "    )\n",
        "\n",
        "    tc = r1.choices[0].message.tool_calls[0]\n",
        "    args = json.loads(tc.function.arguments)\n",
        "    result = TOOL_FUNCTIONS[tc.function.name](**args)\n",
        "\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"   → Tool called : {tc.function.name}\")\n",
        "    print(f\"   → Arguments   : {args}\")\n",
        "    print(f\"   → Tool result : {result}\")\n",
        "\n",
        "    msgs.append(r1.choices[0].message)\n",
        "    msgs.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
        "    r2 = client.chat.completions.create(\n",
        "        model=MODEL, messages=msgs, tools=TOOL_SCHEMAS, temperature=0\n",
        "    )\n",
        "    print(f\"   → Final answer : {r2.choices[0].message.content}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "single_tool_call_demo(\"What does Model & Data Security Insurance cover?\")\n",
        "single_tool_call_demo(\"How much would Agentic AI Liability Insurance cost for a startup?\")\n",
        "single_tool_call_demo(\"Can a healthcare company get coverage from AI Agent Insure?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e339f547",
      "metadata": {},
      "source": [
        "## Part 6: No tool needed — model answers directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553f09ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "general_question = \"What is AI Agent Insure?\"\n",
        "\n",
        "msgs = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You are a helpful assistant for AI Agent Insure, a specialty insurer \"\n",
        "            \"for AI systems, autonomous agents, and ML infrastructure. \"\n",
        "            \"Use the available tools to answer questions accurately.\"\n",
        "        )\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": general_question}\n",
        "]\n",
        "\n",
        "r = client.chat.completions.create(\n",
        "    model=MODEL, messages=msgs, tools=TOOL_SCHEMAS,\n",
        "    tool_choice=\"auto\", temperature=0\n",
        ")\n",
        "\n",
        "# finish_reason will be \"stop\" (not \"tool_calls\") — no tool needed.\n",
        "print(\"Stop reason:\", r.choices[0].finish_reason)\n",
        "print(\"Answer:\", r.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6179d953",
      "metadata": {},
      "source": [
        "## Key concepts\n",
        "\n",
        "- `finish_reason: \"tool_calls\"` → model is mid-task, waiting for a result\n",
        "- `finish_reason: \"stop\"` → model is done\n",
        "- The model never runs Python — it emits a JSON instruction, we execute it\n",
        "- **Next:** Notebook 2 wraps this into an automated loop"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
