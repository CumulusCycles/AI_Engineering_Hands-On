{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-header",
   "metadata": {},
   "source": [
    "# OpenAI Chat Completions API Demo\n",
    "\n",
    "This notebook demonstrates the OpenAI Chat Completions API:\n",
    "- **What it is**: A message-based API for conversational AI\n",
    "- **Why we use it**: Multi-turn conversations, role management, and flexible interactions\n",
    "- **How to use it**: Step-by-step examples from basic to advanced\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Create Virtual Environment\n",
    "\n",
    "    Example:\n",
    "```bash\n",
    "        uv venv --python=python3.12\n",
    "        source .venv/bin/activate\n",
    "        uv pip install -r requirements.txt -q\n",
    "```\n",
    "\n",
    "- Create a `.env` file in the demo directory with your OpenAI API key:\n",
    "```bash\n",
    "        OPENAI_API_KEY=replace-with-your-actual-api-key\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI API key found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API key and gracefully abort if not found\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"⚠️  No OpenAI API key found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "    print(\"   Create a .env file in the demo directory with: OPENAI_API_KEY=your-api-key\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"✓ OpenAI API key found\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Basic Single Message\n",
    "\n",
    "**What:** The simplest Chat Completions call - a single user message.\n",
    "\n",
    "**Why:** This demonstrates the fundamental structure: messages with roles and content.\n",
    "\n",
    "**How:** Send a list with one message containing `role: \"user\"` and `content: \"your question\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (as JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-CxQryYttkTXrs0PPrcD6mDPWVWwEn\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions. Instead of being programmed to carry out specific tasks, machine learning systems learn from data, identifying patterns and making decisions based on that information.\\n\\nKey components of machine learning include:\\n\\n1. **Data**: Machine learning relies heavily on data, which can be structured (e.g., databases) or unstructured (e.g., text, images). The quality and quantity of data significantly impact the performance of machine learning models.\\n\\n2. **Algorithms**: These are the mathematical models and methods used to analyze data and make predictions. Common algorithms include linear regression, decision trees, support vector machines, neural networks, and clustering algorithms.\\n\\n3. **Training**: In the training phase, a model learns from a labeled dataset (in supervised learning) or finds patterns in an unlabeled dataset (in unsupervised learning). The model adjusts its parameters to minimize errors and improve its predictions.\\n\\n4. **Evaluation**: After training, the model's performance is tested using a separate dataset to assess its accuracy and reliability. Metrics such as precision, recall, and F1-score are commonly used for evaluation.\\n\\n5. **Types of Learning**:\\n   - **Supervised Learning**: The model is trained on labeled data, where inputs are mapped to known outputs.\\n   - **Unsupervised Learning**: The model identifies patterns in data without labeled outcomes.\\n   - **Reinforcement Learning**: The model learns to make decisions by taking actions in an environment to maximize a reward.\\n\\nApplications of machine learning are widespread and include areas like natural language processing, computer vision, recommendation systems, fraud detection, and autonomous vehicles, among many others. As the field continues to evolve, machine learning is becoming increasingly integral to various sectors and industries, driving innovation and efficiency.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768280674,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_c4585b5b9c\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 381,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 393,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is machine learning?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Response (as JSON):\")\n",
    "print(json.dumps(response.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f1d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions. Instead of being programmed to carry out specific tasks, machine learning systems learn from data, identifying patterns and making decisions based on that information.\n",
      "\n",
      "Key components of machine learning include:\n",
      "\n",
      "1. **Data**: Machine learning relies heavily on data, which can be structured (e.g., databases) or unstructured (e.g., text, images). The quality and quantity of data significantly impact the performance of machine learning models.\n",
      "\n",
      "2. **Algorithms**: These are the mathematical models and methods used to analyze data and make predictions. Common algorithms include linear regression, decision trees, support vector machines, neural networks, and clustering algorithms.\n",
      "\n",
      "3. **Training**: In the training phase, a model learns from a labeled dataset (in supervised learning) or finds patterns in an unlabeled dataset (in unsupervised learning). The model adjusts its parameters to minimize errors and improve its predictions.\n",
      "\n",
      "4. **Evaluation**: After training, the model's performance is tested using a separate dataset to assess its accuracy and reliability. Metrics such as precision, recall, and F1-score are commonly used for evaluation.\n",
      "\n",
      "5. **Types of Learning**:\n",
      "   - **Supervised Learning**: The model is trained on labeled data, where inputs are mapped to known outputs.\n",
      "   - **Unsupervised Learning**: The model identifies patterns in data without labeled outcomes.\n",
      "   - **Reinforcement Learning**: The model learns to make decisions by taking actions in an environment to maximize a reward.\n",
      "\n",
      "Applications of machine learning are widespread and include areas like natural language processing, computer vision, recommendation systems, fraud detection, and autonomous vehicles, among many others. As the field continues to evolve, machine learning is becoming increasingly integral to various sectors and industries, driving innovation and efficiency.\n"
     ]
    }
   ],
   "source": [
    "# Response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Adding System Role\n",
    "\n",
    "**What:** System messages set high-level behavior, personality, and constraints.\n",
    "\n",
    "**Why:** System messages help control the assistant's tone, style, and behavior without cluttering the conversation.\n",
    "\n",
    "**How:** Add a message with `role: \"system\"` before the user message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "system-role",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data and make decisions or predictions without being explicitly programmed for each task. Instead of giving a computer a set of specific instructions, you provide it with examples and let it figure out patterns and rules on its own.\n",
      "\n",
      "Here’s a simple way to think about it:\n",
      "\n",
      "1. **Data**: The first step involves collecting data, which can be anything from images to numbers to text.\n",
      "\n",
      "2. **Learning**: The machine learning algorithm examines this data to identify patterns. For instance, if it’s looking at photos of cats and dogs, it analyzes features like shapes, colors, and textures.\n",
      "\n",
      "3. **Prediction**: Once it has learned from the data, the machine can make predictions on new, unseen data. For example, you could show it a new photo, and it would tell you whether it's a cat or a dog based on what it has learned.\n",
      "\n",
      "4. **Improvement**: The more data it processes, the better its predictions can become because it continuously learns and refines its understanding.\n",
      "\n",
      "In summary, machine learning is like teaching a computer by showing it examples, rather than giving it strict rules. It’s used in many applications today, like recommendations on streaming services, voice recognition in virtual assistants, and even self-driving cars!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that explains technical concepts in simple terms.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is machine learning?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Multi-Turn Conversation\n",
    "\n",
    "**What:** Building a conversation by including previous messages.\n",
    "\n",
    "**Why:** This demonstrates context retention - the model remembers what was said earlier in the conversation.\n",
    "\n",
    "**How:** Include all previous messages (user and assistant) in the messages list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "multi-turn-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Response:\n",
      "Certainly! Below is a simple non-recursive Python function to calculate the factorial of a non-negative integer:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    \n",
      "    result = 1\n",
      "    for i in range(2, n + 1):\n",
      "        result *= i\n",
      "        \n",
      "    return result\n",
      "\n",
      "# Example usage:\n",
      "print(factorial(5))  # Output: 120\n",
      "```\n",
      "\n",
      "This function checks if the input is a negative number and raises a `ValueError` if so. Otherwise, it computes the factorial using an iterative approach. You can replace the example usage with any non-negative integer to calculate its factorial.\n"
     ]
    }
   ],
   "source": [
    "# First turn\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a simnple, non-recursive Python function to calculate factorial.\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "assistant_message = response.choices[0].message.content\n",
    "print(\"First Response:\")\n",
    "print(assistant_message)\n",
    "\n",
    "# Add assistant's response to the conversation\n",
    "messages.append({\"role\": \"assistant\", \"content\": assistant_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "multi-turn-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Response (with context):\n",
      "Certainly! Below is a recursive implementation of the factorial function in Python:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    elif n == 0 or n == 1:  # Base case\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n - 1)  # Recursive case\n",
      "\n",
      "# Example usage:\n",
      "print(factorial(5))  # Output: 120\n",
      "```\n",
      "\n",
      "In this recursive version, the function calls itself with decremented values of `n` until it reaches the base case, which is `0` or `1`, where it returns `1`. You can use this function to compute the factorial of any non-negative integer.\n"
     ]
    }
   ],
   "source": [
    "# Second turn - the model remembers the previous conversation\n",
    "messages.append({\"role\": \"user\", \"content\": \"Can you make it recursive?\"})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"Second Response (with context):\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Model Comparison\n",
    "\n",
    "**What:** Different models offer different tradeoffs in capability, speed, and cost.\n",
    "\n",
    "**Why:** Understanding model differences helps you choose the right one for your use case.\n",
    "\n",
    "**How:** Call the same prompt with different models and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "model-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gpt-4o-mini:\n",
      "Quantum computing is a type of computation that uses quantum bits (qubits) to perform operations on data in ways that leverage the principles of quantum mechanics, such as superposition and entanglement, allowing for significantly faster processing of certain complex problems compared to classical computers.\n",
      "Tokens used: 67\n",
      "\n",
      "gpt-4o:\n",
      "Quantum computing is a revolutionary technology that leverages the principles of quantum mechanics to perform complex calculations much faster than classical computers.\n",
      "Tokens used: 38\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain quantum computing in one sentence.\"\n",
    "\n",
    "models = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "\n",
    "for model in models:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(f\"Tokens used: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Parameter Exploration: Temperature\n",
    "\n",
    "**What:** Temperature controls randomness/creativity in responses.\n",
    "\n",
    "**Why:** Lower temperature (0.0-0.3) = more deterministic, consistent. Higher temperature (0.7-1.0) = more creative, varied.\n",
    "\n",
    "**How:** Set the `temperature` parameter in the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "temperature-low",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.0 (deterministic):\n",
      "Lines of logic flow,  \n",
      "Fingers dance on keys like rain,  \n",
      "Dreams in code take shape.\n"
     ]
    }
   ],
   "source": [
    "content = \"Write a haiku about coding.\"\n",
    "\n",
    "# Low temperature - deterministic\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content}],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(\"Temperature 0.0 (deterministic):\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "temperature-high",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1.0 (creative):\n",
      "Lines of logic flow,  \n",
      "Fingers dance on keys like dreams,  \n",
      "Worlds born from silence.\n"
     ]
    }
   ],
   "source": [
    "# High temperature - creative\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content}],\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"Temperature 1.0 (creative):\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Max Tokens Control\n",
    "\n",
    "**What:** `max_tokens` limits the length of the response.\n",
    "\n",
    "**Why:** Useful for controlling costs and ensuring responses fit within certain length constraints.\n",
    "\n",
    "**How:** Set the `max_tokens` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "max-tokens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without max_tokens limit:\n",
      "Tokens used: 761\n",
      "Response length: 3506 characters\n",
      "\n",
      "First 200 chars:\n",
      "The Python programming language has a rich history that dates back to the late 1980s. Here’s a timeline highlighting key events in its development:\n",
      "\n",
      "### Late 1980s: Origins\n",
      "- **1980-1989**: Python's c...\n"
     ]
    }
   ],
   "source": [
    "# Without max_tokens\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain the history of Python programming language.\"}]\n",
    ")\n",
    "\n",
    "print(\"Without max_tokens limit:\")\n",
    "print(f\"Tokens used: {response.usage.completion_tokens}\")\n",
    "print(f\"Response length: {len(response.choices[0].message.content)} characters\")\n",
    "print(\"\\nFirst 200 chars:\")\n",
    "print(response.choices[0].message.content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "max-tokens-limited",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With max_tokens=50:\n",
      "Tokens used: 50\n",
      "Response length: 227 characters\n",
      "\n",
      "Response:\n",
      "The Python programming language has an interesting history that dates back to the late 1980s. Here’s a brief overview of its development:\n",
      "\n",
      "### Origins\n",
      "- **Guido van Rossum**: Python was conceived by Guido van Rossum in December\n"
     ]
    }
   ],
   "source": [
    "# With max_tokens limit\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain the history of Python programming language.\"}],\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "print(\"With max_tokens=50:\")\n",
    "print(f\"Tokens used: {response.usage.completion_tokens}\")\n",
    "print(f\"Response length: {len(response.choices[0].message.content)} characters\")\n",
    "print(\"\\nResponse:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Structured Output (JSON Mode)\n",
    "\n",
    "**What:** JSON mode ensures the model responds in valid JSON format.\n",
    "\n",
    "**Why:** Useful when you need to parse the response programmatically and want guaranteed JSON structure.\n",
    "\n",
    "**How:** Set `response_format={\"type\": \"json_object\"}` and instruct the model to return JSON in your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "json-mode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured JSON response:\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"San Francisco\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that returns data in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Extract the following information as JSON: name, age, and city. Person: John, 30 years old, lives in San Francisco.\"}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "import json\n",
    "result = json.loads(response.choices[0].message.content)\n",
    "print(\"Structured JSON response:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83651af3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Chain-of-Thought Reasoning\n",
    "\n",
    "**What:** Chain-of-thought (CoT) prompting encourages the model to show its reasoning process step-by-step before providing an answer.\n",
    "\n",
    "**Why:** CoT improves accuracy on complex problems (math, logic, multi-step reasoning) by making the model's thinking process explicit and allowing it to break down problems into smaller steps.\n",
    "\n",
    "**How:** Add instructions in your prompt asking the model to \"think step by step\" or \"show your reasoning\" before answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17ad24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought Example (Math Problem):\n",
      "Let's break down the problem step by step.\n",
      "\n",
      "1. **Initial Count of Apples**: The store starts with 15 apples.\n",
      "\n",
      "2. **Morning Sales**: In the morning, the store sells 3 apples. \n",
      "   - After the morning sales, the number of apples left can be calculated as:\n",
      "     \\[\n",
      "     15 - 3 = 12 \\text{ apples}\n",
      "     \\]\n",
      "\n",
      "3. **Afternoon Sales**: In the afternoon, the store sells 4 more apples.\n",
      "   - After the afternoon sales, the number of apples left can be calculated as:\n",
      "     \\[\n",
      "     12 - 4 = 8 \\text{ apples}\n",
      "     \\]\n",
      "\n",
      "4. **Delivery of Apples**: The store receives a delivery of 10 more apples.\n",
      "   - Adding the delivery to the current count gives us:\n",
      "     \\[\n",
      "     8 + 10 = 18 \\text{ apples}\n",
      "     \\]\n",
      "\n",
      "5. **Final Count of Apples**: Therefore, at the end of the day, the store has 18 apples.\n",
      "\n",
      "So, the final answer is **18 apples**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chain-of-thought example: Math problem\n",
    "problem = \"A store has 15 apples. They sell 3 apples in the morning and 4 apples in the afternoon. Then they receive a delivery of 10 more apples. How many apples do they have at the end of the day?\"\n",
    "\n",
    "response_cot = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"{problem}\\n\\nThink through this problem step by step, showing your reasoning before giving the final answer.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Chain-of-Thought Example (Math Problem):\")\n",
    "print(response_cot.choices[0].message.content)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6bdc7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought Example (Logic Puzzle):\n",
      "To determine the order of Alice, Bob, and Charlie from front to back, let’s analyze the conditions provided:\n",
      "\n",
      "1. **Alice is not at the front**: This means Alice can either be in the middle or at the back.\n",
      "2. **Bob is not at the back**: This means Bob has to be either at the front or in the middle.\n",
      "3. **Charlie is not in the middle**: This means Charlie must be either at the front or at the back.\n",
      "\n",
      "Now, let's break it down:\n",
      "\n",
      "- From point 3, since Charlie cannot be in the middle, he has to be either at the front or the back. \n",
      "- If Charlie is at the front, then Alice has to be in the middle (since she can't be at the front based on point 1). But if Alice is in the middle, Bob must be at the back, conflicting with point 2. Therefore, Charlie cannot be in the front. This leaves Charlie to be at the back.\n",
      "\n",
      "Now we have:\n",
      "- Charlie at the back.\n",
      "\n",
      "Since Charlie is at the back:\n",
      "- Alice cannot be at the front (from point 1). Therefore, Alice must be in the middle.\n",
      "\n",
      "This leaves Bob to be at the front:\n",
      "- Bob is at the front.\n",
      "\n",
      "Putting all of this together, we have:\n",
      "1. Bob (at the front)\n",
      "2. Alice (in the middle)\n",
      "3. Charlie (at the back)\n",
      "\n",
      "Thus, the order from front to back is: **Bob, Alice, Charlie.**\n"
     ]
    }
   ],
   "source": [
    "# Chain-of-thought example: Logic puzzle\n",
    "logic_puzzle = \"\"\"Three friends - Alice, Bob, and Charlie - are standing in a line. \n",
    "- Alice is not at the front\n",
    "- Bob is not at the back\n",
    "- Charlie is not in the middle\n",
    "\n",
    "What is the order of the three friends from front to back?\"\"\"\n",
    "\n",
    "response_logic = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a logical reasoning assistant. Always show your step-by-step reasoning process before providing your answer.\"},\n",
    "        {\"role\": \"user\", \"content\": logic_puzzle}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Chain-of-Thought Example (Logic Puzzle):\")\n",
    "print(response_logic.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69dbb3a",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "- Chain-of-thought prompting improves accuracy on multi-step problems\n",
    "- Explicitly asking for step-by-step reasoning makes the model's process transparent\n",
    "- Useful for debugging, education, and complex problem-solving scenarios\n",
    "- Can be combined with system messages to enforce CoT behavior consistently\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
