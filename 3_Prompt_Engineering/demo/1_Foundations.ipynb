{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Foundations of Prompt Engineering\n",
    "\n",
    "This notebook covers the fundamental mental models for prompt engineering:\n",
    "- Why prompting is runtime configuration, not clever wording\n",
    "- Prompts as behavior specifications\n",
    "- Message roles and instruction hierarchy\n",
    "- How models resolve conflicts between instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "# We'll use gpt-4o-mini for cost efficiency\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reframing Prompt Engineering\n",
    "\n",
    "### The Wrong Mental Model\n",
    "Most people think prompt engineering is about finding \"magic words\" or clever phrasing.\n",
    "\n",
    "### The Right Mental Model\n",
    "**Prompts are runtime configuration for a probabilistic system.**\n",
    "\n",
    "Think of prompts like:\n",
    "- Function parameters\n",
    "- Configuration files\n",
    "- API request bodies\n",
    "\n",
    "You're not asking questions‚Äîyou're **specifying behavior**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/n1_img1.png\" alt=\"Mental model: prompts as configuration\" width=\"560\" style=\"max-width: 100%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Determinism vs Creativity\n",
    "\n",
    "The same prompt can produce different behaviors based on how you configure it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Deterministic (temperature=0):\n",
      "Here are three outdoor activities you can enjoy:\n",
      "\n",
      "1. **Hiking** - Exploring trails in nature, whether in mountains, forests, or parks, offers a great way to experience the outdoors and get some exercise.\n",
      "\n",
      "2. **Cycling** - Riding a bike on scenic routes, whether on-road or off-road, is a fun way to enjoy the fresh air and explore new areas.\n",
      "\n",
      "3. **Camping** - Spending a night or more in the great outdoors, whether in a tent or a camper, allows you to connect with nature and enjoy activities like cooking over a campfire and stargazing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deterministic configuration (temperature = 0)\n",
    "prompt = \"List 3 outdoor activities.\"\n",
    "\n",
    "response_deterministic = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0  # Most deterministic\n",
    ")\n",
    "\n",
    "print(\"üéØ Deterministic (temperature=0):\")\n",
    "print(response_deterministic.choices[0].message.content)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Creative (temperature=1.5):\n",
      "Here are three outdoor activities you can enjoy:\n",
      "\n",
      "1. **Hiking** - Exploring trails and natural landscapes, whether through forests, mountains, or scenic parks.\n",
      "2. **Cycling** - Riding a bike on roads, trails, or mountain paths is a great way to enjoy the outdoors while getting exercise.\n",
      "3. **Camping** - Spending one or more nights outdoors in a tent or camping vehicle, often combined with activities like cooking, hiking, and fishing.\n"
     ]
    }
   ],
   "source": [
    "# Creative configuration (temperature = 1.5)\n",
    "response_creative = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=1.5  # More creative/random\n",
    ")\n",
    "\n",
    "print(\"üé® Creative (temperature=1.5):\")\n",
    "print(response_creative.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** The prompt text didn't change‚Äîthe *configuration* did. This is engineering, not wordsmithing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Message Roles and Instruction Hierarchy\n",
    "\n",
    "OpenAI's Chat Completions API uses two roles for *your* messages:\n",
    "\n",
    "| Role | Purpose | Priority |\n",
    "|------|---------|----------|\n",
    "| `system` | Behavior specification + application context (user status, rules) | Highest |\n",
    "| `user` | End-user input | Lower |\n",
    "\n",
    "Put application context (e.g. \"user is premium\", \"user is in EU\") in the system message so it's followed reliably. **The model tries to follow system over user when they conflict.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 1: System Message Sets the Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Without system message:\n",
      "I don't have real-time data access to provide current weather conditions. You can check a weather website or app for the latest updates in your area.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without system message\n",
    "response_no_system = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like?\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"‚ùå Without system message:\")\n",
    "print(response_no_system.choices[0].message.content)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¥‚Äç‚ò†Ô∏è With system message (pirate speak):\n",
      "Arrr, matey! I be unable to see the skies from me ship, but ye can check the weather by consultin' a trusty weather map or app. Just be sure to keep an eye out fer storms, lest ye find yerself in a squall! What be yer destination, savvy?\n"
     ]
    }
   ],
   "source": [
    "# With system message\n",
    "response_with_system = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that always responds in pirate speak.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like?\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"üè¥‚Äç‚ò†Ô∏è With system message (pirate speak):\")\n",
    "print(response_with_system.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** The system message controls the *personality* and *behavior* without changing the user's input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 2: Instruction Priority (System vs User)\n",
    "\n",
    "What happens when system and user messages conflict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Conflicting instructions:\n",
      "Photosynthesis is the process by which green plants, algae, and some bacteria convert light energy into chemical energy, primarily in the form of glucose, using carbon dioxide and water.\n",
      "\n",
      "Notice: The system message (concise) wins over the user request (verbose).\n"
     ]
    }
   ],
   "source": [
    "# System says: be concise. User says: be verbose.\n",
    "response_conflict = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Always respond in exactly one sentence. Be extremely concise.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain photosynthesis in great detail with multiple paragraphs.\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"‚öñÔ∏è Conflicting instructions:\")\n",
    "print(response_conflict.choices[0].message.content)\n",
    "print()\n",
    "print(\"Notice: The system message (concise) wins over the user request (verbose).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** System messages have higher priority. This is how you **lock down behavior** even when users try to override it. Put format and constraint instructions (length, tone, structure) in the system message when you want them enforced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 3: Application Context in the System Message\n",
    "\n",
    "Put application context (user status, permissions) in the system message so the model uses it without the user seeing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ With application context in system message:\n",
      "Thank you for reaching out! As a premium member, you have access to priority support. How can I assist you with your account today? If you have any specific issues or questions, feel free to share, and I'll do my best to help you quickly. Additionally, let me know if you're interested in any exclusive features available to premium members!\n"
     ]
    }
   ],
   "source": [
    "# Put application context in the system message (works with all models, including gpt-4o-mini)\n",
    "response_with_context = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a customer support assistant. The user is a premium member. Offer them priority support and exclusive features.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"I need help with my account.\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"üë§ With application context in system message:\")\n",
    "print(response_with_context.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** Include application context in the system message so the model uses it (user status, permissions, etc.) without exposing it in the user-facing conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Locking Behavior vs Allowing Flexibility\n",
    "\n",
    "Use message roles strategically:\n",
    "\n",
    "- **System message:** Non-negotiable behavior (tone, format, constraints) and application context (user permissions, state)\n",
    "- **User message:** End-user intent (what they want to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Locked behavior example:\n",
      "I appreciate your interest in our products! However, I‚Äôm unable to discuss pricing or discounts, as that is handled by our sales team. Additionally, I cannot provide information about future features or their launch timelines. If you have any questions about our existing products, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Example: Customer support chatbot with locked behavior (context in system message)\n",
    "response_locked = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a customer support assistant for TechCorp.\n",
    "Rules:\n",
    "- Always be polite and professional\n",
    "- Never discuss pricing (direct to sales team)\n",
    "- Never make promises about features or timelines\n",
    "- Only answer questions about existing products\n",
    "User account status: free tier, 2 days old.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you give me a discount and tell me when the new feature will launch?\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"üîí Locked behavior example:\")\n",
    "print(response_locked.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** The system message enforces guardrails that the user cannot override."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
