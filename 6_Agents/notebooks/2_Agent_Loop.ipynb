{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef4f81a7",
      "metadata": {},
      "source": [
        "# Notebook 2: The Agent Loop\n",
        "\n",
        "The manual cycle from Notebook 1, wrapped into a `while` loop that keeps running until the model says it's done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
        "from tools import TOOL_SCHEMAS, TOOL_FUNCTIONS\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI()\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a helpful assistant for AI Agent Insure, a specialty insurer for \"\n",
        "    \"AI systems, autonomous agents, and ML infrastructure. \"\n",
        "    \"Use the available tools to answer questions accurately. \"\n",
        "    \"Call as many tools as you need — do not guess when a tool can give you the answer.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d2ae61",
      "metadata": {},
      "source": [
        "## Part 1: The agent loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c5ada0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_agent(user_question: str, max_iterations: int = 10, verbose: bool = True) -> str:\n",
        "    \"\"\"Loop: call model → if tool_calls, execute and append → repeat until stop.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\",   \"content\": user_question}\n",
        "    ]\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        if verbose:\n",
        "            print(f\"--- Iteration {iteration + 1} ---\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=TOOL_SCHEMAS,\n",
        "            tool_choice=\"auto\",\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        choice = response.choices[0]\n",
        "        finish_reason = choice.finish_reason\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  finish_reason: {finish_reason}\")\n",
        "\n",
        "        messages.append(choice.message)\n",
        "\n",
        "        if finish_reason == \"stop\":\n",
        "            return choice.message.content\n",
        "\n",
        "        if finish_reason == \"tool_calls\":\n",
        "            for tool_call in choice.message.tool_calls:\n",
        "                fn_name = tool_call.function.name\n",
        "                fn_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"  → Calling tool : {fn_name}\")\n",
        "                    print(f\"    Arguments    : {fn_args}\")\n",
        "\n",
        "                result = TOOL_FUNCTIONS[fn_name](**fn_args)\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"    Result       : {result}\")\n",
        "\n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"content\": result\n",
        "                })\n",
        "\n",
        "    return f\"[Agent stopped after {max_iterations} iterations without a final answer]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f2b76b3",
      "metadata": {},
      "source": [
        "## Part 2: Single tool call — automated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a45d73d",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = run_agent(\"What does Autonomous Systems & Robotics Coverage include?\")\n",
        "print()\n",
        "print(\"FINAL ANSWER:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae34481e",
      "metadata": {},
      "source": [
        "## Part 3: Two tool calls in sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1a1d14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model calls check_eligibility first, then get_pricing_estimate — we don't tell it to.\n",
        "answer = run_agent(\n",
        "    \"I run a healthcare AI company. Am I eligible for coverage, and if so, \"\n",
        "    \"what would Compliance & Regulatory Shield cost for a mid-market company?\"\n",
        ")\n",
        "print()\n",
        "print(\"FINAL ANSWER:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06763bea",
      "metadata": {},
      "source": [
        "## Part 4: Print the full message history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70de9603",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_agent_with_history(user_question: str, max_iterations: int = 10):\n",
        "    \"\"\"Same as run_agent but also returns the full message history.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\",   \"content\": user_question}\n",
        "    ]\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL, messages=messages,\n",
        "            tools=TOOL_SCHEMAS, tool_choice=\"auto\", temperature=0\n",
        "        )\n",
        "        choice = response.choices[0]\n",
        "        messages.append(choice.message)\n",
        "\n",
        "        if choice.finish_reason == \"stop\":\n",
        "            return choice.message.content, messages\n",
        "\n",
        "        if choice.finish_reason == \"tool_calls\":\n",
        "            for tc in choice.message.tool_calls:\n",
        "                args   = json.loads(tc.function.arguments)\n",
        "                result = TOOL_FUNCTIONS[tc.function.name](**args)\n",
        "                messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
        "\n",
        "    return f\"[Stopped after {max_iterations} iterations]\", messages\n",
        "\n",
        "\n",
        "answer, history = run_agent_with_history(\n",
        "    \"I'm a robotics startup. What coverage do you recommend and what would it cost?\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FULL MESSAGE HISTORY\")\n",
        "print(\"=\" * 60)\n",
        "for i, msg in enumerate(history):\n",
        "    role = msg[\"role\"] if isinstance(msg, dict) else msg.role\n",
        "\n",
        "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "        print(f\"[{i}] ASSISTANT (tool_calls):\")\n",
        "        for tc in msg.tool_calls:\n",
        "            print(f\"     → {tc.function.name}({tc.function.arguments})\")\n",
        "    elif isinstance(msg, dict) and msg.get(\"role\") == \"tool\":\n",
        "        print(f\"[{i}] TOOL RESULT (id={msg['tool_call_id'][:8]}...):\")\n",
        "        print(f\"     {msg['content']}\")\n",
        "    elif hasattr(msg, \"content\") and msg.content:\n",
        "        print(f\"[{i}] {msg.role.upper()}: {msg.content[:200]}\")\n",
        "    elif isinstance(msg, dict) and msg.get(\"content\"):\n",
        "        print(f\"[{i}] {msg['role'].upper()}: {msg['content'][:200]}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d03fb3",
      "metadata": {},
      "source": [
        "## Part 5: Safety guard — max_iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e15568ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# max_iterations=1 forces the loop to stop early — loop runs, tool executes, no final answer.\n",
        "result = run_agent(\n",
        "    \"What does Model & Data Security Insurance cover?\",\n",
        "    max_iterations=1,\n",
        "    verbose=True\n",
        ")\n",
        "print()\n",
        "print(\"Result:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b30b2fa",
      "metadata": {},
      "source": [
        "## Key concepts\n",
        "\n",
        "- The message history is the agent's memory — every tool result is visible on the next iteration\n",
        "- Always include a `max_iterations` guard\n",
        "- **Next:** Notebook 3 adds `search_docs` (RAG as a tool)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
