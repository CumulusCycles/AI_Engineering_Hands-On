{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50b2ab74",
      "metadata": {},
      "source": [
        "# Notebook 3: RAG as a Tool\n",
        "\n",
        "Add a fourth tool — `search_docs` — and let the agent decide when to search the document vs use a structured lookup vs do both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "007177d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import chromadb\n",
        "\n",
        "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
        "from tools import TOOL_SCHEMAS, TOOL_FUNCTIONS\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI()\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "TOP_K = 5\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a helpful assistant for AI Agent Insure, a specialty insurer for \"\n",
        "    \"AI systems, autonomous agents, and ML infrastructure. \"\n",
        "    \"Use search_docs to look up detailed information from the company document. \"\n",
        "    \"Use the other tools for structured lookups (product details, pricing, eligibility). \"\n",
        "    \"Call as many tools as you need — do not guess when a tool can give you the answer.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af21a157",
      "metadata": {},
      "source": [
        "## Part 1: Build the RAG index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bd6c36",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_chunk(path: Path) -> list[str]:\n",
        "    \"\"\"Load a markdown file and split into sentence-level chunks.\"\"\"\n",
        "    doc = path.read_text(encoding=\"utf-8\").strip()\n",
        "    chunks = [s.strip() for s in doc.replace(\"\\n\", \" \").split(\".\") if s.strip()]\n",
        "    return [c + \".\" for c in chunks]\n",
        "\n",
        "\n",
        "data_path = Path(\"../data/AI_Agent_Insure.md\")\n",
        "chunks = load_and_chunk(data_path)\n",
        "print(f\"Loaded {len(chunks)} chunks from {data_path.name}\")\n",
        "\n",
        "resp = client.embeddings.create(model=EMBEDDING_MODEL, input=chunks)\n",
        "embeddings = [r.embedding for r in resp.data]\n",
        "\n",
        "# EphemeralClient = in-memory only, lives for this session.\n",
        "chroma = chromadb.EphemeralClient()\n",
        "coll = chroma.create_collection(\"agent_rag\")\n",
        "coll.add(\n",
        "    ids=[str(i) for i in range(len(chunks))],\n",
        "    embeddings=embeddings,\n",
        "    documents=chunks\n",
        ")\n",
        "print(\"RAG index built and ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277636cf",
      "metadata": {},
      "source": [
        "## Part 2: Wrap RAG as a tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8fea94",
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_docs(query: str) -> str:\n",
        "    \"\"\"Embed the query, retrieve top-k chunks from ChromaDB, return as string.\"\"\"\n",
        "    q_emb = client.embeddings.create(model=EMBEDDING_MODEL, input=[query])\n",
        "    q_vec = q_emb.data[0].embedding\n",
        "\n",
        "    results = coll.query(query_embeddings=[q_vec], n_results=TOP_K)\n",
        "    retrieved = results[\"documents\"][0]\n",
        "\n",
        "    if not retrieved:\n",
        "        return \"No relevant content found in the document for that query.\"\n",
        "\n",
        "    return \"\\n---\\n\".join(retrieved)\n",
        "\n",
        "\n",
        "SEARCH_DOCS_SCHEMA = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"search_docs\",\n",
        "        \"description\": (\n",
        "            \"Search the AI Agent Insure company document for detailed information. \"\n",
        "            \"Use this for questions about company background, mission, operational model, \"\n",
        "            \"claims process, strategic positioning, or anything not covered by the \"\n",
        "            \"other structured tools.\"\n",
        "        ),\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The search query to run against the company document.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"query\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add search_docs to the existing tool list and dispatch dict.\n",
        "ALL_SCHEMAS   = TOOL_SCHEMAS + [SEARCH_DOCS_SCHEMA]\n",
        "ALL_FUNCTIONS = {**TOOL_FUNCTIONS, \"search_docs\": search_docs}\n",
        "\n",
        "print(f\"Agent has {len(ALL_SCHEMAS)} tools: {[s['function']['name'] for s in ALL_SCHEMAS]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9477d285",
      "metadata": {},
      "source": [
        "## Part 3: Agent loop — same logic, extended tool set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f93b8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_agent(user_question: str, max_iterations: int = 10, verbose: bool = True) -> str:\n",
        "    \"\"\"Identical loop to Notebook 2 — only the tool list (ALL_SCHEMAS) has changed.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\",   \"content\": user_question}\n",
        "    ]\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        if verbose:\n",
        "            print(f\"--- Iteration {iteration + 1} ---\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=ALL_SCHEMAS,\n",
        "            tool_choice=\"auto\",\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        choice = response.choices[0]\n",
        "        messages.append(choice.message)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  finish_reason: {choice.finish_reason}\")\n",
        "\n",
        "        if choice.finish_reason == \"stop\":\n",
        "            return choice.message.content\n",
        "\n",
        "        if choice.finish_reason == \"tool_calls\":\n",
        "            for tc in choice.message.tool_calls:\n",
        "                fn_name = tc.function.name\n",
        "                fn_args = json.loads(tc.function.arguments)\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"  → Tool    : {fn_name}\")\n",
        "                    print(f\"    Args    : {fn_args}\")\n",
        "\n",
        "                result = ALL_FUNCTIONS[fn_name](**fn_args)\n",
        "\n",
        "                if verbose:\n",
        "                    # Truncate long RAG results so they don't flood the log.\n",
        "                    preview = result[:300] + \"...\" if len(result) > 300 else result\n",
        "                    print(f\"    Result  : {preview}\")\n",
        "\n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": tc.id,\n",
        "                    \"content\": result\n",
        "                })\n",
        "\n",
        "    return f\"[Agent stopped after {max_iterations} iterations without a final answer]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcfe623b",
      "metadata": {},
      "source": [
        "## Part 4: RAG-only question → `search_docs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49beacbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = run_agent(\"How does AI Agent Insure handle claims and incident response?\")\n",
        "print()\n",
        "print(\"FINAL ANSWER:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f121895b",
      "metadata": {},
      "source": [
        "## Part 5: Structured tool question → `get_pricing_estimate`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d137e255",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = run_agent(\"What would Agentic Workflow Uptime Insurance cost for an enterprise?\")\n",
        "print()\n",
        "print(\"FINAL ANSWER:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11294dd6",
      "metadata": {},
      "source": [
        "## Part 6: Both tools — `search_docs` + `get_pricing_estimate`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfa7469",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = run_agent(\n",
        "    \"Can you explain AI Agent Insure's underwriting philosophy and tell me \"\n",
        "    \"what Model & Data Security Insurance would cost for a startup?\"\n",
        ")\n",
        "print()\n",
        "print(\"FINAL ANSWER:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d008a1",
      "metadata": {},
      "source": [
        "## Part 7: Streamlit app\n",
        "\n",
        "Everything above is packaged into `../app/agent_app.py`.\n",
        "\n",
        "```bash\n",
        "cd 6_Agents/app\n",
        "streamlit run agent_app.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd44698",
      "metadata": {},
      "source": [
        "## Key concepts\n",
        "\n",
        "- RAG is just a tool — the agent decides when to use it\n",
        "- Tool descriptions drive routing — the model reads them to choose\n",
        "- Adding a new tool = one schema + one function in the dispatch dict"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
